{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invasive Species Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create a directory structure and get a small sample of training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "main_path = \"data\\\\\"\n",
    "data_path =\"data\\\\sample\\\\\"\n",
    "#data_path = \"data/dogscats/\"\n",
    "test_path = data_path + \"test\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_path = \"data/\"\n",
    "data_path =\"data/sample/\"\n",
    "#data_path = \"data/\"\n",
    "train_path = data_path + \"train/\"\n",
    "valid_path = data_path + \"valid/\"\n",
    "test_path = data_path + \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import training labels\n",
    "\n",
    "training_labels = pd.read_csv(main_path+'train_labels.csv',index_col=0)\n",
    "training_labels.head(3)\n",
    "type(training_labels.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "#get image names\n",
    "image_names = [filename for filename in glob.glob(main_path + 'train/*')]\n",
    "\n",
    "#if windows replace backslashes (on linux this needs to be commented out)\n",
    "image_names = list(map(lambda x: x.replace(\"\\\\\",\"/\"), image_names))\n",
    "\n",
    "#join names with labels\n",
    "pattern = re.compile(\"\\d+\")\n",
    "image_ids = [pattern.search(x).group() for x in image_names if pattern.search(x) != None]\n",
    "count_non_images = len([pattern.search(x) for x in image_names if pattern.search(x) == None])\n",
    "image_df = pd.DataFrame({'id':image_ids,'filename':image_names[:-2]})\n",
    "image_df.set_index('id',inplace=True)\n",
    "image_df.index = image_df.index.astype(int)\n",
    "image_df = image_df.join(training_labels,how='left')\n",
    "\n",
    "invasive_filenames = image_df[image_df['invasive']==1]['filename']\n",
    "not_invasive_filenames = image_df[image_df['invasive']==0]['filename']\n",
    "\n",
    "invasive_filenames[:3]\n",
    "for filename in invasive_filenames:\n",
    "   shutil.move(filename,main_path+'train/Invasive/')\n",
    "    \n",
    "for filename in not_invasive_filenames:\n",
    "   shutil.move(filename,main_path+'train/Not-invasive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/train/Not-invasive/1.jpg',\n",
       " 'data/train/Not-invasive/10.jpg',\n",
       " 'data/train/Not-invasive/1001.jpg']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create amended paths\n",
    "invasive_filenames_m = [x.replace('train/','train/Invasive/') for x in invasive_filenames]\n",
    "not_invasive_filenames_m = [x.replace('train/','train/Not-invasive/') for x in not_invasive_filenames]\n",
    "#not_invasive_filenames_m[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directory structure for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "def make_sure_path_exists(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "make_sure_path_exists(main_path+'valid/')\n",
    "make_sure_path_exists(main_path+'valid/Invasive')\n",
    "make_sure_path_exists(main_path+'valid/Not-invasive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move 10% data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invasive images moved to validation: 144\n",
      "Not-invasive images moved to validation: 84\n"
     ]
    }
   ],
   "source": [
    "pct=0.1\n",
    "move_invasive_filenames = np.random.choice(invasive_filenames_m,int(pct*len(invasive_filenames_m)),replace=False)\n",
    "print(\"Invasive images moved to validation: \" + str(len(move_invasive_filenames)))\n",
    "move_not_invasive_filenames = np.random.choice(not_invasive_filenames_m,int(pct*len(not_invasive_filenames_m)),replace=False)\n",
    "print(\"Not-invasive images moved to validation: \" + str(len(move_not_invasive_filenames)))\n",
    "\n",
    "for filename in move_invasive_filenames:\n",
    "   shutil.move(filename,main_path+'valid/Invasive/')\n",
    "    \n",
    "for filename in move_not_invasive_filenames:\n",
    "   shutil.move(filename,main_path+'valid/Not-invasive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/valid/Not-invasive/45.jpg',\n",
       " 'data/valid/Not-invasive/1637.jpg',\n",
       " 'data/valid/Not-invasive/291.jpg']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Amend validation filenames\n",
    "#Create amended paths\n",
    "valid_invasive_filenames_m = [x.replace('train/Invasive/','valid/Invasive/') for x in move_invasive_filenames]\n",
    "valid_not_invasive_filenames_m = [x.replace('train/Not-invasive/','valid/Not-invasive/') for x in move_not_invasive_filenames]\n",
    "#valid_invasive_filenames_m[:3]\n",
    "#valid_not_invasive_filenames_m[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy 20% data to sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_sure_path_exists(main_path+'sample/valid/')\n",
    "make_sure_path_exists(main_path+'sample/valid/Invasive')\n",
    "make_sure_path_exists(main_path+'sample/valid/Not-invasive')\n",
    "make_sure_path_exists(main_path+'sample/train/')\n",
    "make_sure_path_exists(main_path+'sample/train/Invasive')\n",
    "make_sure_path_exists(main_path+'sample/train/Not-invasive')\n",
    "make_sure_path_exists(main_path+'sample/test/Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_files_to_sample(prefix,suffix,pct=0.1,windows=False):\n",
    "    image_names = [filename for filename in glob.glob(main_path + prefix + suffix + '*')]\n",
    "    #if windows replace backslashes (on linux this needs to be commented out)\n",
    "    if (windows):\n",
    "        image_names = list(map(lambda x: x.replace(\"\\\\\",\"/\"), image_names))\n",
    "\n",
    "    copy_image_names = np.random.choice(image_names,int(pct*len(image_names)),replace=False)\n",
    "    print(prefix + \", \" + suffix + \" images copied: \" + str(len(copy_image_names)))\n",
    "        \n",
    "    for filename in copy_image_names:\n",
    "       shutil.copy(filename,main_path+'sample/' + prefix + suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pct=0.2\n",
    "windows=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/, Invasive/ images copied: 260\n",
      "train/, Not-invasive/ images copied: 152\n",
      "valid/, Invasive/ images copied: 28\n",
      "valid/, Not-invasive/ images copied: 16\n",
      "test/, Unknown/ images copied: 306\n"
     ]
    }
   ],
   "source": [
    "#get training Invasive image names\n",
    "copy_files_to_sample('train/','Invasive/',pct=pct,windows=windows)\n",
    "copy_files_to_sample('train/','Not-invasive/',pct=pct,windows=windows)\n",
    "copy_files_to_sample('valid/','Invasive/',pct=pct,windows=windows)\n",
    "copy_files_to_sample('valid/','Not-invasive/',pct=pct,windows=windows)\n",
    "copy_files_to_sample('test/','Unknown/',pct=pct,windows=windows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load utils and initialize custom Tensorflow session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from imp import reload\n",
    "import utils; reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 17 05:32:30 2017       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | E486:00:00.0     Off |                    0 |\r\n",
      "| N/A   40C    P0    71W / 149W |     64MiB / 11439MiB |      1%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID  Type  Process name                               Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     42229    C   /anaconda/envs/py35/bin/python                  62MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "make_sure_path_exists(main_path+'results/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:\\Data Science\\GIT\\Invasive-Species-Monitoring\\vgg16.py:105: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
      "L:\\Data Science\\GIT\\Invasive-Species-Monitoring\\vgg16.py:105: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
      "L:\\Data Science\\GIT\\Invasive-Species-Monitoring\\vgg16.py:105: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
      "L:\\Data Science\\GIT\\Invasive-Species-Monitoring\\vgg16.py:105: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 412 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = vgg.get_batches(data_path+'train',batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(data_path+'valid', batch_size=batch_size)\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vgg.model.load_weights(main_path+'results/ft01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches_per_epoch_div = 1\n",
    "epochs_to_run=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:\\Data Science\\GIT\\Invasive-Species-Monitoring\\vgg16.py:218: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  validation_data=val_batches, validation_steps=validation_steps)\n",
      "L:\\Data Science\\GIT\\Invasive-Species-Monitoring\\vgg16.py:218: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_steps=11, steps_per_epoch=103, epochs=1, validation_data=<keras.pre...)`\n",
      "  validation_data=val_batches, validation_steps=validation_steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "103/103 [==============================] - 29s - loss: 0.7175 - acc: 0.7597 - val_loss: 0.6446 - val_acc: 0.7955\n"
     ]
    }
   ],
   "source": [
    "vgg.model.optimizer.lr=0.001\n",
    "vgg.fit(batches,val_batches,nb_epoch=epochs_to_run,steps_per_epoch=(batches.samples // batch_size) // batches_per_epoch_div, validation_steps=val_batches.samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation is run on NVIDIA Tesla K80 with around 11GB RAM. As seen below Tensorflow session keeps the memory allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 17 05:41:14 2017       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | E486:00:00.0     Off |                    0 |\r\n",
      "| N/A   67C    P0    76W / 149W |   9477MiB / 11439MiB |    100%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID  Type  Process name                               Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     42229    C   /anaconda/envs/py35/bin/python                9473MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.model.save_weights(main_path+'results/ft01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:\\Data Science\\GIT\\Invasive-Species-Monitoring\\vgg16.py:218: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  validation_data=val_batches, validation_steps=validation_steps)\n",
      "L:\\Data Science\\GIT\\Invasive-Species-Monitoring\\vgg16.py:218: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_steps=11, steps_per_epoch=103, epochs=1, validation_data=<keras.pre...)`\n",
      "  validation_data=val_batches, validation_steps=validation_steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "103/103 [==============================] - 27s - loss: 0.4881 - acc: 0.8301 - val_loss: 0.9108 - val_acc: 0.7045\n"
     ]
    }
   ],
   "source": [
    "vgg.model.optimizer.lr=0.0003\n",
    "vgg.fit(batches,val_batches,nb_epoch=epochs_to_run,steps_per_epoch=(batches.samples // batch_size) // batches_per_epoch_div, validation_steps=val_batches.samples // batch_size)\n",
    "vgg.model.save_weights(main_path+'results/ft02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:\\Data Science\\GIT\\Invasive-Species-Monitoring\\vgg16.py:218: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  validation_data=val_batches, validation_steps=validation_steps)\n",
      "L:\\Data Science\\GIT\\Invasive-Species-Monitoring\\vgg16.py:218: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_steps=11, steps_per_epoch=103, epochs=1, validation_data=<keras.pre...)`\n",
      "  validation_data=val_batches, validation_steps=validation_steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "103/103 [==============================] - 27s - loss: 0.3849 - acc: 0.8859 - val_loss: 0.9568 - val_acc: 0.7955\n"
     ]
    }
   ],
   "source": [
    "vgg.fit(batches,val_batches,nb_epoch=epochs_to_run,steps_per_epoch=(batches.samples // batch_size) // batches_per_epoch_div, validation_steps=val_batches.samples // batch_size)\n",
    "vgg.model.save_weights(main_path+'results/ft03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vgg.model.optimizer.lr = 0.00003\n",
    "vgg.fit(batches,val_batches,nb_epoch=epochs_to_run,steps_per_epoch=(batches.samples // batch_size) // batches_per_epoch_div, validation_steps=val_batches.samples // batch_size)\n",
    "vgg.model.save_weights(main_path+'results/ft04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.model.optimizer.lr = 0.000001\n",
    "vgg.fit(batches,val_batches,nb_epoch=epochs_to_run,steps_per_epoch=(batches.samples // batch_size) // batches_per_epoch_div, validation_steps=val_batches.samples // batch_size)\n",
    "vgg.model.save_weights(main_path+'results/ft05.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Windows version\n",
    "vgg.model.load_weights(main_path+'results\\\\ft05.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score using roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44 images belonging to 2 classes.\n",
      "11/11 [==============================] - 2s     \n",
      "ROC AUC score on validation data: 0.904017857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "val_batches2 = vgg.get_batches(valid_path,shuffle=False,batch_size=batch_size,class_mode=None)\n",
    "val_probs = vgg.model.predict_generator(val_batches2,steps = val_batches2.samples // batch_size, verbose=1)\n",
    "val_labels = val_batches2.classes\n",
    "print(\"ROC AUC score on validation data: \" + str(roc_auc_score(val_labels,val_probs[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = vgg.get_batches(test_path,shuffle=False,batch_size=batch_size,class_mode=None)\n",
    "print(test_batches.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = vgg.model.predict_generator(test_batches, steps = test_batches.samples // (batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = test_batches.filenames\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction.shape)\n",
    "print(prediction[:5])\n",
    "prediction_trim = prediction[:len(filenames)]\n",
    "print(prediction_trim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_clip = np.clip(prediction_trim,0.02,0.98)\n",
    "prediction_clip[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Windows version\n",
    "#from PIL import Image\n",
    "#Image.open(test_path.replace(\"/\",\"\\\\\")+filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#print(prediction[0])\n",
    "print(filenames[0])\n",
    "Image.open(test_path+filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isdog = prediction_clip[:,1]\n",
    "isdog[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile('\\d+')\n",
    "ids = [pattern.search(x).group() for x in filenames]\n",
    "ids[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ids))\n",
    "print(len(isdog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_idx(idx, titles=None):\n",
    "    plots([image.load_img(data_path + 'test/' + i) for i in idx], titles=titles)\n",
    "n_view=8\n",
    "\n",
    "df = pd.DataFrame({'id':ids,'label':isdog})\n",
    "df['id'] = df['id'].astype(int)\n",
    "df = df.set_index('id')\n",
    "print(df.head())\n",
    "f_names = permutation(filenames)[:n_view]\n",
    "idx = [pattern.search(x).group() for x in f_names]\n",
    "plot_idx(f_names,list(df.loc[np.array(idx).astype(int),'label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = permutation(filenames)[:n_view]\n",
    "idx = [pattern.search(x).group() for x in f_names]\n",
    "plot_idx(f_names,list(df.loc[np.array(idx).astype(int),'label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = permutation(filenames)[:n_view]\n",
    "idx = [pattern.search(x).group() for x in f_names]\n",
    "plot_idx(f_names,list(df.loc[np.array(idx).astype(int),'label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "subm_df = pd.DataFrame({'id':ids,'label':isdog})\n",
    "subm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df['id'] = subm_df['id'].astype(int)\n",
    "subm_df['label'] = np.round(subm_df['label'],5)\n",
    "print(subm_df.info())\n",
    "print(subm_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_df.to_csv(main_path + 'results/' + 'subm011.csv',index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('data/dogscats/results/' + 'subm011.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df = pd.read_csv(main_path + 'results/' + 'subm002.csv')\n",
    "print(subm_df.info())\n",
    "subm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df.loc[:,'label'] = 1 - subm_df['label']\n",
    "#subm_df.columns = ['iid','label']\n",
    "subm_df.loc[:,'label'] = np.round(subm_df['label'],5)\n",
    "subm_df.sort_values('id',inplace=True)\n",
    "subm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_df.to_csv(main_path + 'results/' + 'subm005.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('data/dogscats/results/' + 'subm005.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.model.load_weights(main_path+'results/ft04.h5')\n",
    "batch_size=100\n",
    "val_batches2 = vgg.get_batches(data_path+'valid', shuffle=False, batch_size=batch_size, class_mode=None)\n",
    "val_probs = vgg.model.predict_generator(val_batches2, steps = val_batches2.samples // (batch_size),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_labels = val_batches2.classes\n",
    "val_filenames = val_batches2.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_isCat_probs = val_probs[:,0]\n",
    "val_preds = np.round(1-val_isCat_probs)\n",
    "val_isCat_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number of images to check\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helped function for plotting images and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_idx(idx, titles=None):\n",
    "    plots([image.load_img(data_path + 'valid/' + val_filenames[i]) for i in idx], titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.where(val_preds == val_labels)[0]\n",
    "idx = permutation(correct)[:n_view]\n",
    "plot_idx(idx,val_isCat_probs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a few incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(val_preds != val_labels)[0]\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plot_idx(idx,val_isCat_probs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confident predictions for invasive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_cats = np.where((val_preds==0) & (val_preds==val_labels))[0]\n",
    "most_correct_cats = np.argsort(val_isCat_probs[correct_cats])[-n_view:]\n",
    "plot_idx(correct_cats[most_correct_cats], val_isCat_probs[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confident predictions for not-invasive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_dogs = np.where((val_preds==1) & (val_preds==val_labels))[0]\n",
    "most_correct_dogs = np.argsort(val_isCat_probs[correct_dogs])[:n_view]\n",
    "plot_idx(correct_dogs[most_correct_dogs], val_isCat_probs[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot incorrectly predicted invasive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_cats = np.where((val_preds==0) & (val_preds != val_labels))[0]\n",
    "most_incorrect_cats = np.argsort(val_isCat_probs[incorrect_cats])[::-1][:n_view]\n",
    "plot_idx(incorrect_cats[most_incorrect_cats], val_isCat_probs[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot incorrectly predicted not-invasive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_dogs = np.where((val_preds==1) & (val_preds != val_labels))[0]\n",
    "most_incorrect_dogs = np.argsort(val_isCat_probs[incorrect_dogs])[::-1][:n_view]\n",
    "plot_idx(incorrect_dogs[most_incorrect_dogs], val_isCat_probs[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the most uncertain predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(np.abs(val_isCat_probs-0.5))\n",
    "plot_idx(most_uncertain[:n_view], val_isCat_probs[most_uncertain][:n_view])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(val_labels,val_preds)\n",
    "plot_confusion_matrix(cm, val_batches2.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_labels,val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
